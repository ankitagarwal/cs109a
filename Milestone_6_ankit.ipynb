{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "**<font size=8><center>Milestone 6</center></font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=6>Introduction</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are four baseline models for the Lending Club analysis. These are simple models that treat the problem as binary classification. The outcomes can either be \"default\" or \"not default\". These models take simplicitic views of the problem and serve as baselines for comparison and sanity check when more sofisiticated models are built in later parts of the project.\n",
    "\n",
    "The models are:\n",
    "1. predict all outcomes to be \"not default\";\n",
    "2. predict all outcomes of borrowers with lowest credit scores to always :default\" and others \"not default\";\n",
    "3. model outcomes with a single predictor \"grade\";\n",
    "4. model outcomes with a single predictor \"interest rate\".\n",
    "\n",
    "The data cleaning steps are from milestone 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "Devon Luongo <br>\n",
    "Ankit Agarwal <br>\n",
    "Bryn Clark <br>\n",
    "Ben Yuen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankit/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#new imports for milestone 4\n",
    "import StringIO\n",
    "from IPython.display import Image\n",
    "#import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics  import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/home/ankit/anaconda2/pkgs/basemap-1.0.7-np111py27_0/lib/python2.7/site-packages/mpl_toolkits/basemap/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=6>Data Cleaning</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data files have fields that contain NAs for older time periods. In order to collapse the data sets into one file, all numerical data will be stored in float fields (integer fields do not support NA missing values). To do this, we first define a conversion dictionary that stores the numeric fields with lookups to the *float* data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convert_float = dict([s, float] for s in\n",
    "                     ['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'installment',\n",
    "                      'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'mths_since_last_delinq',                      \n",
    "                      'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'total_acc',\n",
    "                      'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
    "                      'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
    "                      'last_pymnt_amnt', 'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
    "                      'annual_inc_joint', 'dti_joint', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', \n",
    "                      'open_acc_6m', 'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', \n",
    "                      'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', \n",
    "                      'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', \n",
    "                      'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util',\n",
    "                      'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct',\n",
    "                      'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc',\n",
    "                      'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq',\n",
    "                      'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', \n",
    "                      'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
    "                      'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
    "                      'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq',\n",
    "                      'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim',\n",
    "                      'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a dictionary of string fields, to handle situations where the inferred data type might be numeric even though the field should be read in as a string/object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_str = dict([s, str] for s in\n",
    "                    ['term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', \n",
    "                     'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'url', 'desc', \n",
    "                     'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', \n",
    "                     'initial_list_status', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d',\n",
    "                     'policy_code', 'application_type', 'verification_status_joint'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the input data from the CSV data files using pandas *read_csv*. There is a blank row in the data header and there are two blank rows in the footer of each file. To allow the use of *skip_footer*, we use the python engine rather than the C engine. The first two columns (*id* and *member_id*) are unique and used to create a table index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankit/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: FutureWarning: The 'skip_footer' argument has been deprecated and will be removed in a future version. Please use the 'skipfooter' argument instead.\n",
      "/home/ankit/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:15: FutureWarning: The 'skip_footer' argument has been deprecated and will be removed in a future version. Please use the 'skipfooter' argument instead.\n",
      "/home/ankit/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:23: FutureWarning: The 'skip_footer' argument has been deprecated and will be removed in a future version. Please use the 'skipfooter' argument instead.\n",
      "/home/ankit/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:31: FutureWarning: The 'skip_footer' argument has been deprecated and will be removed in a future version. Please use the 'skipfooter' argument instead.\n"
     ]
    }
   ],
   "source": [
    "data_2007_2011 = pd.read_csv(\"./data/LoanStats3a.csv\",\n",
    "                   skiprows=1,\n",
    "                   skip_footer=2,\n",
    "                   engine=\"python\",\n",
    "                   na_values=['NaN', 'nan'],\n",
    "                   converters=convert_str,\n",
    "                   index_col=[0,1])\n",
    "\n",
    "data_2014 = pd.read_csv(\"./data/LoanStats3b.csv\",\n",
    "                   skiprows=1,\n",
    "                   skip_footer=2,\n",
    "                   engine=\"python\",\n",
    "                   na_values=['NaN', 'nan'],\n",
    "                   converters=convert_str,\n",
    "                   index_col=[0,1])\n",
    "\n",
    "data_2015 = pd.read_csv(\"./data/LoanStats3c.csv\",\n",
    "                   skiprows=1,\n",
    "                   skip_footer=2,\n",
    "                   engine=\"python\",\n",
    "                   na_values=['NaN', 'nan'],\n",
    "                   converters=convert_str,\n",
    "                   index_col=[0,1])\n",
    "\n",
    "data = pd.read_csv(\"./data/LoanStats3d.csv\",\n",
    "                   skiprows=1,\n",
    "                   skip_footer=2,\n",
    "                   engine=\"python\",\n",
    "                   na_values=['NaN', 'nan'],\n",
    "                   converters=convert_str,\n",
    "                   index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table dimensions 2007-2011: 42536 x 109\n",
      "Data table dimensions 2014: 188181 x 109\n",
      "Data table dimensions 2015: 235629 x 109\n",
      "Data table dimensions 2016: 421095 x 109\n"
     ]
    }
   ],
   "source": [
    "print \"Data table dimensions 2007-2011: %d x %d\" % data_2007_2011.shape\n",
    "\n",
    "print \"Data table dimensions 2014: %d x %d\" % data_2014.shape\n",
    " \n",
    "print \"Data table dimensions 2015: %d x %d\" % data_2015.shape\n",
    "\n",
    "print \"Data table dimensions 2016: %d x %d\" % data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the specific dataset used, the numeric values may be read in as integers. For best performance and to enable mergining of the datasets, we convert those fields to floats (which allow NaN values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in convert_float.items():\n",
    "    data_2007_2011[k] = data_2007_2011[k].astype(v)\n",
    "    data_2014[k] = data_2014[k].astype(v)\n",
    "    data_2015[k] = data_2015[k].astype(v)\n",
    "    data[k] = data[k].astype(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data types after the float conversion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object fields need some more processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 object fields that contain dates in the format *YYYY-MMM* (e.g. '2010-Jan'). We parse those to return datetime fields, which are more easily input into time series models or plotted in charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.issue_d = pd.to_datetime(data.issue_d, errors=\"coerce\")\n",
    "data.last_pymnt_d = pd.to_datetime(data.last_pymnt_d, errors=\"coerce\")\n",
    "data.next_pymnt_d = pd.to_datetime(data.next_pymnt_d, errors=\"coerce\")\n",
    "data.last_credit_pull_d = pd.to_datetime(data.last_credit_pull_d, errors=\"coerce\")\n",
    "data.earliest_cr_line = pd.to_datetime(data.earliest_cr_line, errors=\"coerce\")\n",
    "\n",
    "data_2007_2011.issue_d = pd.to_datetime(data_2007_2011.issue_d, errors=\"coerce\")\n",
    "data_2007_2011.last_pymnt_d = pd.to_datetime(data_2007_2011.last_pymnt_d, errors=\"coerce\")\n",
    "data_2007_2011.next_pymnt_d = pd.to_datetime(data_2007_2011.next_pymnt_d, errors=\"coerce\")\n",
    "data_2007_2011.last_credit_pull_d = pd.to_datetime(data_2007_2011.last_credit_pull_d, errors=\"coerce\")\n",
    "data_2007_2011.earliest_cr_line = pd.to_datetime(data_2007_2011.earliest_cr_line, errors=\"coerce\")\n",
    "\n",
    "data_2014.issue_d = pd.to_datetime(data_2014.issue_d, errors=\"coerce\")\n",
    "data_2014.last_pymnt_d = pd.to_datetime(data_2014.last_pymnt_d, errors=\"coerce\")\n",
    "data_2014.next_pymnt_d = pd.to_datetime(data_2014.next_pymnt_d, errors=\"coerce\")\n",
    "data_2014.last_credit_pull_d = pd.to_datetime(data_2014.last_credit_pull_d, errors=\"coerce\")\n",
    "data_2014.earliest_cr_line = pd.to_datetime(data_2014.earliest_cr_line, errors=\"coerce\")\n",
    "\n",
    "data_2015.issue_d = pd.to_datetime(data_2015.issue_d, errors=\"coerce\")\n",
    "data_2015.last_pymnt_d = pd.to_datetime(data_2015.last_pymnt_d, errors=\"coerce\")\n",
    "data_2015.next_pymnt_d = pd.to_datetime(data_2015.next_pymnt_d, errors=\"coerce\")\n",
    "data_2015.last_credit_pull_d = pd.to_datetime(data_2015.last_credit_pull_d, errors=\"coerce\")\n",
    "data_2015.earliest_cr_line = pd.to_datetime(data_2015.earliest_cr_line, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the remaining fields contain categorical data. We use the pandas *category* data type to store the data more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.term = pd.Categorical(data.term, categories= [\" 36 months\", \" 60 months\", \"None\"])\n",
    "data.grade = pd.Categorical(data.grade, categories=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"None\"])\n",
    "data.sub_grade = pd.Categorical(data.sub_grade, categories=[\"A1\", \"A2\", \"A3\", \"A4\", \"A5\",\n",
    "                                                            \"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \n",
    "                                                            \"C1\", \"C2\", \"C3\", \"C4\", \"C5\",\n",
    "                                                            \"D1\", \"D2\", \"D3\", \"D4\", \"D5\",\n",
    "                                                            \"E1\", \"E2\", \"E3\", \"E4\", \"E5\",\n",
    "                                                            \"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\n",
    "                                                            \"G1\", \"G2\", \"G3\", \"G4\", \"G5\",\n",
    "                                                            \"None\"])\n",
    "data.home_ownership = pd.Categorical(data.home_ownership.str.title(), categories=[\"Own\", \"Mortgage\", \"Rent\", \"Any\", \"Other\", \"None\"])\n",
    "data.emp_length = pd.Categorical(data.emp_length, categories=[\"< 1 year\", \"1 year\", \"2 years\", \"3 years\",\n",
    "                                                              \"4 years\", \"5 years\", \"6 years\", \"7 years\",\n",
    "                                                              \"8 years\", \"9 years\", \"10+ years\", \"n/a\", \"None\"])\n",
    "data.verification_status = pd.Categorical(data.verification_status, categories=[\"Verified\", \"Source Verified\", \"Not Verified\", \"None\"])\n",
    "data.loan_status = pd.Categorical(data.loan_status, categories=[\"Fully Paid\", \"Current\", \"Charged Off\",\n",
    "                                                                \"Does not meet the credit policy. Status:Fully Paid\",\n",
    "                                                                \"Does not meet the credit policy. Status:Charged Off\",\n",
    "                                                                \"In Grace Period\", \"Late (16-30 days)\", \"Late (31-120 days)\",\n",
    "                                                                \"Default\", \"None\"])\n",
    "data.pymnt_plan = pd.Categorical(data.pymnt_plan.str.title(), categories=[\"Y\", \"N\", \"None\"])\n",
    "data.purpose = pd.Categorical(data.purpose.str.title(),\n",
    "                              categories=[\"Debt_Consolidation\", \"Credit_Card\", \"Home_Improvement\", \"Major_Purchase\", \n",
    "                                          \"Small_Business\", \"Car\", \"Wedding\", \"Medical\", \"Moving\", \"House\",\n",
    "                                          \"Educational\", \"Vacation\", \"Renewable_Energy\", \"Other\", \"None\"])\n",
    "data.addr_state = pd.Categorical(data.addr_state,\n",
    "                                 categories=[\"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\",\n",
    "                                             \"GA\", \"HI\", \"IA\", \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\",\n",
    "                                             \"MD\", \"ME\", \"MI\", \"MN\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\", \"NE\",\n",
    "                                             \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\",\n",
    "                                             \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"VT\", \"WA\", \"WI\", \"WV\",\n",
    "                                             \"WY\", \"None\"])\n",
    "data.initial_list_status = pd.Categorical(data.initial_list_status, categories=[\"f\", \"w\", \"None\"])\n",
    "data.policy_code = pd.Categorical(data.policy_code, categories=[\"1\", \"None\"])\n",
    "data.application_type = pd.Categorical(data.application_type.str.title(), categories=[\"Individual\", \"Joint\", \"None\"])\n",
    "data.verification_status_joint = pd.Categorical(data.verification_status_joint, categories=[\"Verified\", \"Source Verified\", \"Not Verified\", \"None\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2007_2011.term = pd.Categorical(data_2007_2011.term, categories= [\" 36 months\", \" 60 months\", \"None\"])\n",
    "data_2007_2011.grade = pd.Categorical(data_2007_2011.grade, categories=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"None\"])\n",
    "data_2007_2011.sub_grade = pd.Categorical(data_2007_2011.sub_grade, categories=[\"A1\", \"A2\", \"A3\", \"A4\", \"A5\",\n",
    "                                                            \"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \n",
    "                                                            \"C1\", \"C2\", \"C3\", \"C4\", \"C5\",\n",
    "                                                            \"D1\", \"D2\", \"D3\", \"D4\", \"D5\",\n",
    "                                                            \"E1\", \"E2\", \"E3\", \"E4\", \"E5\",\n",
    "                                                            \"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\n",
    "                                                            \"G1\", \"G2\", \"G3\", \"G4\", \"G5\",\n",
    "                                                            \"None\"])\n",
    "data_2007_2011.home_ownership = pd.Categorical(data_2007_2011.home_ownership.str.title(), categories=[\"Own\", \"Mortgage\", \"Rent\", \"Any\", \"Other\", \"None\"])\n",
    "data_2007_2011.emp_length = pd.Categorical(data_2007_2011.emp_length, categories=[\"< 1 year\", \"1 year\", \"2 years\", \"3 years\",\n",
    "                                                              \"4 years\", \"5 years\", \"6 years\", \"7 years\",\n",
    "                                                              \"8 years\", \"9 years\", \"10+ years\", \"n/a\", \"None\"])\n",
    "data_2007_2011.verification_status = pd.Categorical(data_2007_2011.verification_status, categories=[\"Verified\", \"Source Verified\", \"Not Verified\", \"None\"])\n",
    "data_2007_2011.loan_status = pd.Categorical(data_2007_2011.loan_status, categories=[\"Fully Paid\", \"Current\", \"Charged Off\",\n",
    "                                                                \"Does not meet the credit policy. Status:Fully Paid\",\n",
    "                                                                \"Does not meet the credit policy. Status:Charged Off\",\n",
    "                                                                \"In Grace Period\", \"Late (16-30 days)\", \"Late (31-120 days)\",\n",
    "                                                                \"Default\", \"None\"])\n",
    "data_2007_2011.pymnt_plan = pd.Categorical(data_2007_2011.pymnt_plan.str.title(), categories=[\"Y\", \"N\", \"None\"])\n",
    "data_2007_2011.purpose = pd.Categorical(data_2007_2011.purpose.str.title(),\n",
    "                              categories=[\"Debt_Consolidation\", \"Credit_Card\", \"Home_Improvement\", \"Major_Purchase\", \n",
    "                                          \"Small_Business\", \"Car\", \"Wedding\", \"Medical\", \"Moving\", \"House\",\n",
    "                                          \"Educational\", \"Vacation\", \"Renewable_Energy\", \"Other\", \"None\"])\n",
    "data_2007_2011.addr_state = pd.Categorical(data_2007_2011.addr_state,\n",
    "                                 categories=[\"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\",\n",
    "                                             \"GA\", \"HI\", \"IA\", \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\",\n",
    "                                             \"MD\", \"ME\", \"MI\", \"MN\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\", \"NE\",\n",
    "                                             \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\",\n",
    "                                             \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"VT\", \"WA\", \"WI\", \"WV\",\n",
    "                                             \"WY\", \"None\"])\n",
    "data_2007_2011.initial_list_status = pd.Categorical(data_2007_2011.initial_list_status, categories=[\"f\", \"w\", \"None\"])\n",
    "data_2007_2011.policy_code = pd.Categorical(data_2007_2011.policy_code, categories=[\"1\", \"None\"])\n",
    "data_2007_2011.application_type = pd.Categorical(data_2007_2011.application_type.str.title(), categories=[\"Individual\", \"Joint\", \"None\"])\n",
    "data_2007_2011.verification_status_joint = pd.Categorical(data_2007_2011.verification_status_joint, categories=[\"Verified\", \"Source Verified\", \"Not Verified\", \"None\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2014.term = pd.Categorical(data_2014.term, categories= [\" 36 months\", \" 60 months\", \"None\"])\n",
    "data_2014.grade = pd.Categorical(data_2014.grade, categories=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"None\"])\n",
    "data_2014.sub_grade = pd.Categorical(data_2014.sub_grade, categories=[\"A1\", \"A2\", \"A3\", \"A4\", \"A5\",\n",
    "                                                            \"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \n",
    "                                                            \"C1\", \"C2\", \"C3\", \"C4\", \"C5\",\n",
    "                                                            \"D1\", \"D2\", \"D3\", \"D4\", \"D5\",\n",
    "                                                            \"E1\", \"E2\", \"E3\", \"E4\", \"E5\",\n",
    "                                                            \"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\n",
    "                                                            \"G1\", \"G2\", \"G3\", \"G4\", \"G5\",\n",
    "                                                            \"None\"])\n",
    "data_2014.home_ownership = pd.Categorical(data_2014.home_ownership.str.title(), categories=[\"Own\", \"Mortgage\", \"Rent\", \"Any\", \"Other\", \"None\"])\n",
    "data_2014.emp_length = pd.Categorical(data_2014.emp_length, categories=[\"< 1 year\", \"1 year\", \"2 years\", \"3 years\",\n",
    "                                                              \"4 years\", \"5 years\", \"6 years\", \"7 years\",\n",
    "                                                              \"8 years\", \"9 years\", \"10+ years\", \"n/a\", \"None\"])\n",
    "data_2014.verification_status = pd.Categorical(data_2014.verification_status, categories=[\"Verified\", \"Source Verified\", \"Not Verified\", \"None\"])\n",
    "data_2014.loan_status = pd.Categorical(data_2014.loan_status, categories=[\"Fully Paid\", \"Current\", \"Charged Off\",\n",
    "                                                                \"Does not meet the credit policy. Status:Fully Paid\",\n",
    "                                                                \"Does not meet the credit policy. Status:Charged Off\",\n",
    "                                                                \"In Grace Period\", \"Late (16-30 days)\", \"Late (31-120 days)\",\n",
    "                                                                \"Default\", \"None\"])\n",
    "data_2014.pymnt_plan = pd.Categorical(data_2014.pymnt_plan.str.title(), categories=[\"Y\", \"N\", \"None\"])\n",
    "data_2014.purpose = pd.Categorical(data_2014.purpose.str.title(),\n",
    "                              categories=[\"Debt_Consolidation\", \"Credit_Card\", \"Home_Improvement\", \"Major_Purchase\", \n",
    "                                          \"Small_Business\", \"Car\", \"Wedding\", \"Medical\", \"Moving\", \"House\",\n",
    "                                          \"Educational\", \"Vacation\", \"Renewable_Energy\", \"Other\", \"None\"])\n",
    "data_2014.addr_state = pd.Categorical(data_2014.addr_state,\n",
    "                                 categories=[\"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\",\n",
    "                                             \"GA\", \"HI\", \"IA\", \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\",\n",
    "                                             \"MD\", \"ME\", \"MI\", \"MN\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\", \"NE\",\n",
    "                                             \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\",\n",
    "                                             \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"VT\", \"WA\", \"WI\", \"WV\",\n",
    "                                             \"WY\", \"None\"])\n",
    "data_2014.initial_list_status = pd.Categorical(data_2014.initial_list_status, categories=[\"f\", \"w\", \"None\"])\n",
    "data_2014.policy_code = pd.Categorical(data_2014.policy_code, categories=[\"1\", \"None\"])\n",
    "data_2014.application_type = pd.Categorical(data_2014.application_type.str.title(), categories=[\"Individual\", \"Joint\", \"None\"])\n",
    "data_2014.verification_status_joint = pd.Categorical(data_2014.verification_status_joint, categories=[\"Verified\", \"Source Verified\", \"Not Verified\", \"None\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2015.term = pd.Categorical(data_2015.term, categories= [\" 36 months\", \" 60 months\", \"None\"])\n",
    "data_2015.grade = pd.Categorical(data_2015.grade, categories=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"None\"])\n",
    "data_2015.sub_grade = pd.Categorical(data_2015.sub_grade, categories=[\"A1\", \"A2\", \"A3\", \"A4\", \"A5\",\n",
    "                                                            \"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \n",
    "                                                            \"C1\", \"C2\", \"C3\", \"C4\", \"C5\",\n",
    "                                                            \"D1\", \"D2\", \"D3\", \"D4\", \"D5\",\n",
    "                                                            \"E1\", \"E2\", \"E3\", \"E4\", \"E5\",\n",
    "                                                            \"F1\", \"F2\", \"F3\", \"F4\", \"F5\",\n",
    "                                                            \"G1\", \"G2\", \"G3\", \"G4\", \"G5\",\n",
    "                                                            \"None\"])\n",
    "data_2015.home_ownership = pd.Categorical(data_2015.home_ownership.str.title(), categories=[\"Own\", \"Mortgage\", \"Rent\", \"Any\", \"Other\", \"None\"])\n",
    "data_2015.emp_length = pd.Categorical(data_2015.emp_length, categories=[\"< 1 year\", \"1 year\", \"2 years\", \"3 years\",\n",
    "                                                              \"4 years\", \"5 years\", \"6 years\", \"7 years\",\n",
    "                                                              \"8 years\", \"9 years\", \"10+ years\", \"n/a\", \"None\"])\n",
    "data_2015.verification_status = pd.Categorical(data_2015.verification_status, categories=[\"Verified\", \"Source Verified\", \"Not Verified\", \"None\"])\n",
    "data_2015.loan_status = pd.Categorical(data_2015.loan_status, categories=[\"Fully Paid\", \"Current\", \"Charged Off\",\n",
    "                                                                \"Does not meet the credit policy. Status:Fully Paid\",\n",
    "                                                                \"Does not meet the credit policy. Status:Charged Off\",\n",
    "                                                                \"In Grace Period\", \"Late (16-30 days)\", \"Late (31-120 days)\",\n",
    "                                                                \"Default\", \"None\"])\n",
    "data_2015.pymnt_plan = pd.Categorical(data_2015.pymnt_plan.str.title(), categories=[\"Y\", \"N\", \"None\"])\n",
    "data_2015.purpose = pd.Categorical(data_2015.purpose.str.title(),\n",
    "                              categories=[\"Debt_Consolidation\", \"Credit_Card\", \"Home_Improvement\", \"Major_Purchase\", \n",
    "                                          \"Small_Business\", \"Car\", \"Wedding\", \"Medical\", \"Moving\", \"House\",\n",
    "                                          \"Educational\", \"Vacation\", \"Renewable_Energy\", \"Other\", \"None\"])\n",
    "data_2015.addr_state = pd.Categorical(data_2015.addr_state,\n",
    "                                 categories=[\"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\",\n",
    "                                             \"GA\", \"HI\", \"IA\", \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\",\n",
    "                                             \"MD\", \"ME\", \"MI\", \"MN\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\", \"NE\",\n",
    "                                             \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\",\n",
    "                                             \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"VT\", \"WA\", \"WI\", \"WV\",\n",
    "                                             \"WY\", \"None\"])\n",
    "data_2015.initial_list_status = pd.Categorical(data_2015.initial_list_status, categories=[\"f\", \"w\", \"None\"])\n",
    "data_2015.policy_code = pd.Categorical(data_2015.policy_code, categories=[\"1\", \"None\"])\n",
    "data_2015.application_type = pd.Categorical(data_2015.application_type.str.title(), categories=[\"Individual\", \"Joint\", \"None\"])\n",
    "data_2015.verification_status_joint = pd.Categorical(data_2015.verification_status_joint, categories=[\"Verified\", \"Source Verified\", \"Not Verified\", \"None\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the categorical data conversion, we check a table listing Null values for each field. If any categories were excluded inadvertently, the *Null Count* in this table would show up as > 0. The *verification_status_joint* field does not appear to contain valid data for the datasets that have been analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some percentages are stored as strings (*int_rate*, *revol_util*). Here we convert them into a float by stripping the % symbol and dividing by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percent_to_float(s):\n",
    "    if (type(s) == str):\n",
    "        if (\"%\" in s):\n",
    "            return float(str(s).strip(\"%\"))/100\n",
    "        else:\n",
    "            if s == \"None\":\n",
    "                return np.nan\n",
    "            else:            \n",
    "                return s\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "data.int_rate = [percent_to_float(s) for s in data.int_rate]\n",
    "data.revol_util = [percent_to_float(s) for s in data.revol_util]\n",
    "\n",
    "data_2007_2011.int_rate = [percent_to_float(s) for s in data_2007_2011.int_rate]\n",
    "data_2007_2011.revol_util = [percent_to_float(s) for s in data_2007_2011.revol_util]\n",
    "\n",
    "data_2014.int_rate = [percent_to_float(s) for s in data_2014.int_rate]\n",
    "data_2014.revol_util = [percent_to_float(s) for s in data_2014.revol_util]\n",
    "\n",
    "data_2015.int_rate = [percent_to_float(s) for s in data_2015.int_rate]\n",
    "data_2015.revol_util = [percent_to_float(s) for s in data_2015.revol_util]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887441, 109)\n"
     ]
    }
   ],
   "source": [
    "# We merge all data frames into a single one.\n",
    "fulldf = pd.concat([data, data_2007_2011, data_2014, data_2015])\n",
    "print fulldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current                                                467679\n",
      "Fully Paid                                             315192\n",
      "Charged Off                                             75740\n",
      "Late (31-120 days)                                      14548\n",
      "In Grace Period                                          8432\n",
      "Late (16-30 days)                                        2968\n",
      "Does not meet the credit policy. Status:Fully Paid       1988\n",
      "Does not meet the credit policy. Status:Charged Off       761\n",
      "Default                                                   132\n",
      "None                                                        1\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let us see what status we have.\n",
    "print fulldf[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391064, 109)\n",
      "0    315192\n",
      "1     75872\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ok we dont want current or None status as we don't know what is going to happen with those.\n",
    "# next also late and grace period we are not sure about.\n",
    "# thirdly we remove loans that do not meet credit policy so we can convert our issue to a binar model\n",
    "fulldf = fulldf[((fulldf[\"loan_status\"] == \"Default\") | (fulldf[\"loan_status\"] == \"Charged Off\") | (fulldf[\"loan_status\"] == \"Fully Paid\"))]\n",
    "\n",
    "# Rename \"Charged off to default\"\n",
    "fulldf[\"loan_status\"] = fulldf[\"loan_status\"].replace(\"Charged Off\", \"Default\")\n",
    "fulldf[\"loan_status\"] = fulldf[\"loan_status\"].replace(\"Default\", 1)\n",
    "fulldf[\"loan_status\"] = fulldf[\"loan_status\"].replace(\"Fully Paid\", 0)\n",
    "print fulldf.shape\n",
    "print fulldf[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Drop object columns, deal with these in another way?\n",
    "# for col in fulldf.columns:\n",
    "#     if fulldf[col].dtype != \"object\":\n",
    "#         fulldf = fulldf.drop(col, axis=1)\n",
    "# print fulldf.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391064, 108)\n"
     ]
    }
   ],
   "source": [
    "y = fulldf[\"loan_status\"]\n",
    "X = fulldf.drop(\"loan_status\", axis=1)\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75872, 108)\n",
      "(315192, 108)\n"
     ]
    }
   ],
   "source": [
    "y_def = y[y==1]\n",
    "y_paid = y[y==0]\n",
    "X_def = X[y==1]\n",
    "X_paid = X[y==0]\n",
    "\n",
    "print X_def.shape\n",
    "print X_paid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "def feature_plot(X, y, estimators):\n",
    "\n",
    "    # Build a forest and compute the feature importances\n",
    "    forest = ExtraTreesClassifier(n_estimators=estimators,\n",
    "                                  random_state=0)\n",
    "\n",
    "    forest.fit(X, y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print X_paid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107392, 108)\n",
      "(107392, 108)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-c6485495d980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_def\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mX_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ankit/anaconda2/lib/python2.7/site-packages/pandas/core/reshape.pyc\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m         result = _get_dummies_1d(data, prefix, prefix_sep, dummy_na,\n\u001b[0;32m-> 1102\u001b[0;31m                                  sparse=sparse, drop_first=drop_first)\n\u001b[0m\u001b[1;32m   1103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ankit/anaconda2/lib/python2.7/site-packages/pandas/core/reshape.pyc\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1107\u001b[0m                     sparse=False, drop_first=False):\n\u001b[1;32m   1108\u001b[0m     \u001b[0;31m# Series avoids inconsistent NaN handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m     \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_factorize_from_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_empty_Frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ankit/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 241\u001b[0;31m                                        raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ankit/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2946\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2948\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data must be 1-dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2949\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2950\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_paid, y_paid, test_size=0.10, random_state=42)\n",
    "X_input = np.concatenate([X_test, X_def])\n",
    "print X_input.shape\n",
    "y_input = np.concatenate([y_test, y_def])\n",
    "print X_input.shape\n",
    "X_input = pd.get_dummies(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
