{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "**<font size=5><center>Predicting Default Rates for Lending Club</center></font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "Devon Luongo <br>\n",
    "Ankit Agarwal <br>\n",
    "Bryn Clarke <br>\n",
    "Ben Yuen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_X = pd.read_pickle(\"./data/df_X.pkl\")\n",
    "df_y = pd.read_pickle(\"./data/df_y.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"./data/X_train.npy\")\n",
    "X_test = np.load(\"./data/X_test.npy\")\n",
    "y_train = np.load(\"./data/y_train.npy\")\n",
    "y_test = np.load(\"./data/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline models\n",
    "# All positive (label every applicant as default)\n",
    "class Pos_model(object):\n",
    "    def fit(self, X, y):\n",
    "        return\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.array([1] * len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "\n",
    "pos_model = Pos_model()\n",
    "pos_model.fit(X_train, y_train)\n",
    "pos_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All negative (label every applicant as not default)\n",
    "class Neg_model(object):\n",
    "    def fit(self, X, y):\n",
    "        return\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.array([0] * len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "\n",
    "neg_model = Neg_model()\n",
    "neg_model.fit(X_train, y_train)\n",
    "neg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random (randomly predict flu or not flu)\n",
    "class Random_model(object):\n",
    "    def fit(self, X, y):\n",
    "        return\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.random.randint(0, 2, len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "\n",
    "random_model = Random_model()\n",
    "random_model.fit(X_train, y_train)\n",
    "random_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_cost(y, y_pred):\n",
    "    cost_fixed_application = 10.0\n",
    "    cost_fixed_servicing = 100.0\n",
    "    cost_default = 15000.0\n",
    "    cost_interest = -1000.0\n",
    "    \n",
    "    # TRUE POSITIVE: Predict default, applicant would default\n",
    "    n_true_positive = sum((y==1) & (y_pred==1))\n",
    "    # We only pay fixed application processing costs as we decline the loan\n",
    "    cost_true_positive = n_true_positive*(cost_fixed_application)\n",
    "    \n",
    "    # TRUE NEGATIVE: Predict pay on time, applicant will pay on time\n",
    "    n_true_negative = sum((y==0) & (y_pred==0))\n",
    "    # We pay fixed application processing costs, costs of servicing the loan, and gain profit on interest payments\n",
    "    cost_true_negative = n_true_negative*(cost_fixed_application + cost_fixed_servicing + cost_interest)\n",
    "    \n",
    "    # FALSE POSITIVE: Predict default, applicant would pay on time\n",
    "    n_false_positive = sum((y==0) & (y_pred==1))\n",
    "    # We only pay fixed application processing costs as we decline the loan\n",
    "    cost_false_positive = n_false_positive*(cost_fixed_application)\n",
    "    \n",
    "    # FALSE NEGATIVE: Predict pay on time, applicant will default\n",
    "    n_false_negative = sum((y==1) & (y_pred==0))\n",
    "    # We pay fixed application processing costs, costs of servicing the loan, and the principal as the loan defaults\n",
    "    cost_false_negative = n_false_negative*(cost_fixed_application + cost_fixed_servicing + cost_default)\n",
    "    \n",
    "    return cost_true_positive + cost_true_negative + cost_false_positive + cost_false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_cost</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>average_precision_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive Model (All Default)</th>\n",
       "      <td>1173200.0</td>\n",
       "      <td>0.196514</td>\n",
       "      <td>0.598257</td>\n",
       "      <td>0.328477</td>\n",
       "      <td>27.752072</td>\n",
       "      <td>0.196514</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Model (None Default)</th>\n",
       "      <td>264465200.0</td>\n",
       "      <td>0.803486</td>\n",
       "      <td>0.598257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Model (Half Default)</th>\n",
       "      <td>130635400.0</td>\n",
       "      <td>0.500904</td>\n",
       "      <td>0.398010</td>\n",
       "      <td>0.284253</td>\n",
       "      <td>17.286490</td>\n",
       "      <td>0.195895</td>\n",
       "      <td>0.49486</td>\n",
       "      <td>0.498365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               custom_cost  accuracy_score  \\\n",
       "Model                                                        \n",
       "Positive Model (All Default)     1173200.0        0.196514   \n",
       "Negative Model (None Default)  264465200.0        0.803486   \n",
       "Random Model (Half Default)    130635400.0        0.500904   \n",
       "\n",
       "                               average_precision_score  f1_score   log_loss  \\\n",
       "Model                                                                         \n",
       "Positive Model (All Default)                  0.598257  0.328477  27.752072   \n",
       "Negative Model (None Default)                 0.598257  0.000000   6.787346   \n",
       "Random Model (Half Default)                   0.398010  0.284253  17.286490   \n",
       "\n",
       "                               precision_score  recall_score  roc_auc_score  \n",
       "Model                                                                        \n",
       "Positive Model (All Default)          0.196514       1.00000       0.500000  \n",
       "Negative Model (None Default)         0.000000       0.00000       0.500000  \n",
       "Random Model (Half Default)           0.195895       0.49486       0.498365  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compare_models(models, labels, scoring_funcs):\n",
    "    all_scores = []\n",
    "    \n",
    "    for scoring_func in scoring_funcs:    \n",
    "        scores = []\n",
    "    \n",
    "        for model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            scores.append(scoring_func(y_test, y_pred))\n",
    "    \n",
    "        res = pd.DataFrame({\"Model\": labels, scoring_func.__name__: scores})\n",
    "        res.set_index(\"Model\", inplace=True)\n",
    "        all_scores.append(res)\n",
    "    \n",
    "    return pd.concat(all_scores, axis=1)\n",
    "    \n",
    "compare_models([pos_model, neg_model, random_model],\n",
    "               [\"Positive Model (All Default)\", \"Negative Model (None Default)\", \"Random Model (Half Default)\"],\n",
    "               [custom_cost, accuracy_score, average_precision_score, f1_score, log_loss, precision_score, recall_score, roc_auc_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log1 = LogisticRegression(penalty='l2', C=1.0, class_weight=None)\n",
    "log2 = LogisticRegression(penalty='l2', C=1.0, class_weight='balanced')\n",
    "lda1 = LDA(priors=None)\n",
    "lda2 = LDA(priors=[0.5, 0.5])\n",
    "lda3 = LDA(priors=[0.2, 0.8])\n",
    "qda1 = QDA(priors=None, reg_param=0.0)\n",
    "qda2 = QDA(priors=[0.2, 0.8], reg_param=0.0)\n",
    "qda3 = QDA(priors=[0.2, 0.8], reg_param=0.9)\n",
    "knn1 = KNN(n_neighbors=1, weights='uniform', p=2)\n",
    "knn2 = KNN(n_neighbors=5, weights='uniform', p=2)\n",
    "knn3 = KNN(n_neighbors=5, weights='distance', p=2)\n",
    "knn4 = KNN(n_neighbors=5, weights='uniform', p=1)\n",
    "tree1 = DecisionTree(criterion='gini', max_depth=3, class_weight=None)\n",
    "tree2 = DecisionTree(criterion='entropy', max_depth=3, class_weight=None)\n",
    "tree3 = DecisionTree(criterion='gini', max_depth=10, class_weight=None)\n",
    "tree4 = DecisionTree(criterion='gini', max_depth=3, class_weight='balanced')\n",
    "rf1 = RandomForest(n_estimators=10, max_depth=3)\n",
    "rf2 = RandomForest(n_estimators=10, max_depth=3, class_weight='balanced')\n",
    "rf3 = RandomForest(n_estimators=10, max_depth=1, class_weight='balanced')\n",
    "svc1 = SVC(C=1.0, kernel='linear', class_weight=None)\n",
    "svc2 = SVC(C=1.0, kernel='linear', class_weight='balanced')\n",
    "svc3 = SVC(C=0.5, kernel='linear', class_weight='balanced')\n",
    "svc4 = SVC(C=2.0, kernel='linear', class_weight='balanced')\n",
    "svc5 = SVC(C=1.0, kernel='rbf', class_weight='balanced')\n",
    "\n",
    "compare_models([log1, log2,\n",
    "                lda1, lda2, lda3,\n",
    "                qda1, qda2, qda3,\n",
    "                knn1, knn2, knn3, knn4,\n",
    "                tree1, tree2, tree3, tree4,\n",
    "                rf1, rf2, rf3,\n",
    "                svc1, svc2, svc3, svc4, svc5],\n",
    "               [\"Logistic Regression (unweighted)\",\n",
    "                \"Logistic Regression (balanced)\",\n",
    "                \"LDA (no priors)\",\n",
    "                \"LDA (equal weight priors)\",\n",
    "                \"LDA (penalizing priors)\",\n",
    "                \"QDA (no priors/no reg)\",\n",
    "                \"QDA (penal. priors/no reg)\",\n",
    "                \"QDA (penal. priors/with reg)\",\n",
    "                \"1-NN (uniform L2 weights)\",\n",
    "                \"5-NN (uniform L2 weights)\",\n",
    "                \"5-NN (distance L2 weights)\",\n",
    "                \"5-NN (uniform L1 weights)\",\n",
    "                \"DTree (gini/3-depth)\",\n",
    "                \"DTree (entropy/3-depth)\",\n",
    "                \"DTree (gini/10-depth)\",\n",
    "                \"DTree (gini/10-depth/balanced)\",\n",
    "                \"RForest (10 est/3-depth)\",\n",
    "                \"RForest (10 est/3-depth/balanced)\",\n",
    "                \"RForest (10 est/1-depth/balanced)\",\n",
    "                \"SVC (linear/C=1.0)\",\n",
    "                \"SVC (linear/C=1.0/balanced)\",\n",
    "                \"SVC (linear/C=0.5/balanced)\",\n",
    "                \"SVC (linear/C=2.0/balanced)\",\n",
    "                \"SVC (rbf/C=1.0/balanced)\"],\n",
    "               [custom_cost, accuracy_score, average_precision_score, f1_score, log_loss, precision_score, recall_score, roc_auc_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "\n",
    "def scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return custom_cost(y, y_pred)\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForest(n_estimators=200)\n",
    "\n",
    "param_grid = {\"max_depth\": [3, 5, None],\n",
    "              \"max_features\": [1, 3, 10, 100],\n",
    "              \"min_samples_split\": [10, 30, 100],\n",
    "              \"min_samples_leaf\": [10, 30, 100],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, scoring=scoring)\n",
    "start = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time.time() - start, len(grid_search.cv_results_['params'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs109a_proj]",
   "language": "python",
   "name": "conda-env-cs109a_proj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
