{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "**<font size=5><center>Predicting Default Rates for Lending Club</center></font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "Devon Luongo <br>\n",
    "Ankit Agarwal <br>\n",
    "Bryn Clarke <br>\n",
    "Ben Yuen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#new imports for milestone 4\n",
    "import StringIO\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics  import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##df_X = pd.read_pickle(\"./data/df_X.pkl\")\n",
    "df_y = pd.read_pickle(\"./data/df_y.pkl\")\n",
    "with open('./data/df_X_imputed.pkl', 'rb') as f:\n",
    "    df_X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"./data/X_train.npy\")\n",
    "X_test = np.load(\"./data/X_test.npy\")\n",
    "y_train = np.load(\"./data/y_train.npy\")\n",
    "y_test = np.load(\"./data/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_sm = df_X.values[0:1000, :]\n",
    "y_sm = df_y.values[1000:1200]\n",
    "\n",
    "print df_y.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X.values, df_y.values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Baseline models\n",
    "# All positive (label every applicant as default)\n",
    "class Pos_model(object):\n",
    "    def fit(self, X, y):\n",
    "        return\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.array([1] * len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "\n",
    "pos_model = Pos_model()\n",
    "pos_model.fit(X_train, y_train)\n",
    "pos_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All negative (label every applicant as not default)\n",
    "class Neg_model(object):\n",
    "    def fit(self, X, y):\n",
    "        return\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.array([0] * len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "\n",
    "neg_model = Neg_model()\n",
    "neg_model.fit(X_train, y_train)\n",
    "neg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random (randomly predict flu or not flu)\n",
    "class Random_model(object):\n",
    "    def fit(self, X, y):\n",
    "        return\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.random.randint(0, 2, len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "\n",
    "random_model = Random_model()\n",
    "random_model.fit(X_train, y_train)\n",
    "random_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_cost(y, y_pred):\n",
    "    cost_fixed_application = 10.0\n",
    "    cost_fixed_servicing = 100.0\n",
    "    cost_default = 15000.0\n",
    "    cost_interest = -1000.0\n",
    "    \n",
    "    # TRUE POSITIVE: Predict default, applicant would default\n",
    "    n_true_positive = sum((y==1) & (y_pred==1))\n",
    "    # We only pay fixed application processing costs as we decline the loan\n",
    "    cost_true_positive = n_true_positive*(cost_fixed_application)\n",
    "    \n",
    "    # TRUE NEGATIVE: Predict pay on time, applicant will pay on time\n",
    "    n_true_negative = sum((y==0) & (y_pred==0))\n",
    "    # We pay fixed application processing costs, costs of servicing the loan, and gain profit on interest payments\n",
    "    cost_true_negative = n_true_negative*(cost_fixed_application + cost_fixed_servicing + cost_interest)\n",
    "    \n",
    "    # FALSE POSITIVE: Predict default, applicant would pay on time\n",
    "    n_false_positive = sum((y==0) & (y_pred==1))\n",
    "    # We only pay fixed application processing costs as we decline the loan\n",
    "    cost_false_positive = n_false_positive*(cost_fixed_application)\n",
    "    \n",
    "    # FALSE NEGATIVE: Predict pay on time, applicant will default\n",
    "    n_false_negative = sum((y==1) & (y_pred==0))\n",
    "    # We pay fixed application processing costs, costs of servicing the loan, and the principal as the loan defaults\n",
    "    cost_false_negative = n_false_negative*(cost_fixed_application + cost_fixed_servicing + cost_default)\n",
    "    \n",
    "    return cost_true_positive + cost_true_negative + cost_false_positive + cost_false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compare_models(models, labels, scoring_funcs):\n",
    "    all_scores = []\n",
    "    \n",
    "    for scoring_func in scoring_funcs:    \n",
    "        scores = []\n",
    "    \n",
    "        for model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            scores.append(scoring_func(y_test, y_pred))\n",
    "    \n",
    "        res = pd.DataFrame({\"Model\": labels, scoring_func.__name__: scores})\n",
    "        res.set_index(\"Model\", inplace=True)\n",
    "        all_scores.append(res)\n",
    "    \n",
    "    return pd.concat(all_scores, axis=1)\n",
    "    \n",
    "compare_models([pos_model, neg_model, random_model],\n",
    "               [\"Positive Model (All Default)\", \"Negative Model (None Default)\", \"Random Model (Half Default)\"],\n",
    "               [custom_cost, accuracy_score, average_precision_score, f1_score, log_loss, precision_score, recall_score, roc_auc_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log1 = LogisticRegression(penalty='l2', C=1.0, class_weight=None)\n",
    "log2 = LogisticRegression(penalty='l2', C=1.0, class_weight='balanced')\n",
    "lda1 = LDA(priors=None)\n",
    "lda2 = LDA(priors=[0.5, 0.5])\n",
    "lda3 = LDA(priors=[0.2, 0.8])\n",
    "qda1 = QDA(priors=None, reg_param=0.0)\n",
    "qda2 = QDA(priors=[0.2, 0.8], reg_param=0.0)\n",
    "qda3 = QDA(priors=[0.2, 0.8], reg_param=0.9)\n",
    "knn1 = KNN(n_neighbors=1, weights='uniform', p=2)\n",
    "knn2 = KNN(n_neighbors=5, weights='uniform', p=2)\n",
    "knn3 = KNN(n_neighbors=5, weights='distance', p=2)\n",
    "knn4 = KNN(n_neighbors=5, weights='uniform', p=1)\n",
    "tree1 = DecisionTree(criterion='gini', max_depth=3, class_weight=None)\n",
    "tree2 = DecisionTree(criterion='entropy', max_depth=3, class_weight=None)\n",
    "tree3 = DecisionTree(criterion='gini', max_depth=10, class_weight=None)\n",
    "tree4 = DecisionTree(criterion='gini', max_depth=3, class_weight='balanced')\n",
    "rf1 = RandomForest(n_estimators=10, max_depth=3)\n",
    "rf2 = RandomForest(n_estimators=10, max_depth=3, class_weight='balanced')\n",
    "rf3 = RandomForest(n_estimators=10, max_depth=1, class_weight='balanced')\n",
    "svc1 = SVC(C=1.0, kernel='linear', class_weight=None)\n",
    "svc2 = SVC(C=1.0, kernel='linear', class_weight='balanced')\n",
    "svc3 = SVC(C=0.5, kernel='linear', class_weight='balanced')\n",
    "svc4 = SVC(C=2.0, kernel='linear', class_weight='balanced')\n",
    "svc5 = SVC(C=1.0, kernel='rbf', class_weight='balanced')\n",
    "\n",
    "compare_models([log1, log2,\n",
    "                lda1, lda2, lda3,\n",
    "                qda1, qda2, qda3,\n",
    "                knn1, knn2, knn3, knn4,\n",
    "                tree1, tree2, tree3, tree4,\n",
    "                rf1, rf2, rf3,\n",
    "                svc1, svc2, svc3, svc4, svc5],\n",
    "               [\"Logistic Regression (unweighted)\",\n",
    "                \"Logistic Regression (balanced)\",\n",
    "                \"LDA (no priors)\",\n",
    "                \"LDA (equal weight priors)\",\n",
    "                \"LDA (penalizing priors)\",\n",
    "                \"QDA (no priors/no reg)\",\n",
    "                \"QDA (penal. priors/no reg)\",\n",
    "                \"QDA (penal. priors/with reg)\",\n",
    "                \"1-NN (uniform L2 weights)\",\n",
    "                \"5-NN (uniform L2 weights)\",\n",
    "                \"5-NN (distance L2 weights)\",\n",
    "                \"5-NN (uniform L1 weights)\",\n",
    "                \"DTree (gini/3-depth)\",\n",
    "                \"DTree (entropy/3-depth)\",\n",
    "                \"DTree (gini/10-depth)\",\n",
    "                \"DTree (gini/10-depth/balanced)\",\n",
    "                \"RForest (10 est/3-depth)\",\n",
    "                \"RForest (10 est/3-depth/balanced)\",\n",
    "                \"RForest (10 est/1-depth/balanced)\",\n",
    "                \"SVC (linear/C=1.0)\",\n",
    "                \"SVC (linear/C=1.0/balanced)\",\n",
    "                \"SVC (linear/C=0.5/balanced)\",\n",
    "                \"SVC (linear/C=2.0/balanced)\",\n",
    "                \"SVC (rbf/C=1.0/balanced)\"],\n",
    "               [custom_cost, accuracy_score, average_precision_score, f1_score, log_loss, precision_score, recall_score, roc_auc_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "#Compute ROC Curve\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(LogisticRegression(penalty='l2', fit_intercept=True, solver='lbfgs', multi_class='multinomial'))\n",
    "y_score = classifier.fit(x_train_sm, y_train_sm).decision_function(x_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(10):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_sm[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_sm.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print stop - start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot Roc Curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "#Compute ROC Curve\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "y_score = classifier.fit(x_train_sm, y_train_sm).decision_function(x_test_sm)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(10):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_sm[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_sm.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot Roc Curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs109a_proj]",
   "language": "python",
   "name": "conda-env-cs109a_proj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
